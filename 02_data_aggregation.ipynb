{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "936b8dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeria/opt/anaconda3/lib/python3.9/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rate\n",
      "as_of_date      0.000000\n",
      "delayable       0.210084\n",
      "social          0.210084\n",
      "staple          0.210084\n",
      "work_related    0.210084\n",
      "dtype: float64\n",
      "Zero rate\n",
      "as_of_date\n",
      "0.0\n",
      "delayable\n",
      "0.002105263157894737\n",
      "social\n",
      "0.0\n",
      "staple\n",
      "0.0\n",
      "work_related\n",
      "0.004210526315789474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/8zh8_jv54k5___mhhnhk40580000gn/T/ipykernel_34523/826538718.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataset_i_clean.columns = dataset_i_clean.columns.str.replace(r'\\d+', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rate\n",
      "as_of_date      0.0\n",
      "delayable       0.0\n",
      "social          0.0\n",
      "staple          0.0\n",
      "work_related    0.0\n",
      "dtype: float64\n",
      "Zero rate\n",
      "as_of_date\n",
      "0.0\n",
      "delayable\n",
      "0.0\n",
      "social\n",
      "0.0\n",
      "staple\n",
      "0.0\n",
      "work_related\n",
      "0.0\n",
      "Missing rate\n",
      "as_of_date      0.0\n",
      "delayable       0.0\n",
      "social          0.0\n",
      "staple          0.0\n",
      "work_related    0.0\n",
      "dtype: float64\n",
      "Zero rate\n",
      "as_of_date\n",
      "0.0\n",
      "delayable\n",
      "0.0\n",
      "social\n",
      "0.0\n",
      "staple\n",
      "0.0\n",
      "work_related\n",
      "0.0\n",
      "Missing rate\n",
      "as_of_date      0.0\n",
      "delayable       0.0\n",
      "social          0.0\n",
      "staple          0.0\n",
      "work_related    0.0\n",
      "dtype: float64\n",
      "Zero rate\n",
      "as_of_date\n",
      "0.0\n",
      "delayable\n",
      "0.0\n",
      "social\n",
      "0.0\n",
      "staple\n",
      "0.0\n",
      "work_related\n",
      "0.0\n",
      "Missing rate\n",
      "as_of_date      0.0\n",
      "delayable       0.0\n",
      "social          0.0\n",
      "staple          0.0\n",
      "work_related    0.0\n",
      "dtype: float64\n",
      "Zero rate\n",
      "as_of_date\n",
      "0.0\n",
      "delayable\n",
      "0.0\n",
      "social\n",
      "0.0\n",
      "staple\n",
      "0.0\n",
      "work_related\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "##\n",
    "## Name: 02_data_aggregation.ipynb\n",
    "## Purpose: \n",
    "## Author: VDR\n",
    "## Email: dellarocca.vale@gmail.com\n",
    "## Date: 2021-12-05\n",
    "## Version: v1\n",
    "##\n",
    "###############################################################################\n",
    "##\n",
    "## Notes: Same output of what provided in April, just rewritten in Python\n",
    "##\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "\n",
    "## 0. General set up ----------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import datetime\n",
    "from data_quality_checks_vdr import data_quality_checks_f\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from functools import reduce\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "cols_to_keep = [\"as_of_date\", \"delayable\", \"social\", \"staple\", \"work_related\"]\n",
    "cols_to_keep_ea = [\"as_of_date\", \"a_delayable\", \"a_social\", \"a_staple\", \"a_work_related\"]\n",
    "\n",
    "\n",
    "\n",
    "## 1. Read the files downloaded with the previous code --------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "dataset_cs = pd.read_excel(\"raw_data/card_spending_021221.xlsx\", sheet_name = 1, index_col = None, skiprows = 3, dtype = str).head(6)\n",
    "dataset_i = pd.read_excel(\"raw_data/ios_data_ios1.xlsx\", sheet_name = 0, index_col = None, dtype = str).iloc[6:]\n",
    "dataset_f = pd.read_excel(\"raw_data/furlough_data.xlsx\", sheet_name = \"3. Time series by sector\", header = 3, dtype = str)[:-5]\n",
    "dataset_e = pd.read_excel(\"raw_data/employment_data.xls\", sheet_name = 1, header = 5, dtype = str).iloc[11:][:-16]\n",
    "dataset_v = pd.read_excel(\"raw_data/vacancies_data.xls\", sheet_name = 1, header = 3, dtype = str).iloc[4:][:-9]\n",
    "dataset_e_additional = pd.read_excel(\"raw_data/employment_additional.xls\", sheet_name = 1, header = 5, dtype = str).iloc[3:][:-18]\n",
    "\n",
    "\n",
    "## 2. Card spending cleaning and quality check ------------------------------------------------------\n",
    "\n",
    "dataset_cs_clean = np.transpose(dataset_cs)\n",
    "\n",
    "\n",
    "## We will first clean the column names, given the inconsistent format\n",
    "new_header = dataset_cs_clean.iloc[0]\n",
    "dataset_cs_clean = dataset_cs_clean[1:]\n",
    "dataset_cs_clean.columns = new_header\n",
    "dataset_cs_clean.columns = [c.replace(' ', '_') for c in dataset_cs_clean.columns]\n",
    "dataset_cs_clean.columns = [x.lower() for x in dataset_cs_clean.columns]\n",
    "\n",
    "\n",
    "## We will now create new variables as % change compared to the previous reporting date\n",
    "dataset_cs_clean[\"lag_delayable\"] = dataset_cs_clean.delayable.shift()\n",
    "dataset_cs_clean[\"lag_social\"] = dataset_cs_clean.social.shift()\n",
    "dataset_cs_clean[\"lag_staple\"] = dataset_cs_clean.staple.shift()\n",
    "dataset_cs_clean[\"lag_work_related\"] = dataset_cs_clean.work_related.shift()\n",
    "\n",
    "\n",
    "dataset_cs_clean[\"delayable\"] = (dataset_cs_clean.delayable.astype(float) - dataset_cs_clean.lag_delayable.astype(float))/dataset_cs_clean.lag_delayable.astype(float)\n",
    "dataset_cs_clean[\"social\"] = (dataset_cs_clean.social.astype(float) - dataset_cs_clean.lag_social.astype(float))/dataset_cs_clean.lag_social.astype(float)\n",
    "dataset_cs_clean[\"staple\"] = (dataset_cs_clean.staple.astype(float) - dataset_cs_clean.lag_staple.astype(float))/dataset_cs_clean.lag_staple.astype(float)\n",
    "dataset_cs_clean[\"work_related\"] = (dataset_cs_clean.work_related.astype(float) - dataset_cs_clean.lag_work_related.astype(float))/dataset_cs_clean.lag_work_related.astype(float)\n",
    "\n",
    "\n",
    "## Formatting date\n",
    "dataset_cs_clean[\"as_of_date\"] = dataset_cs_clean[\"category\"]\n",
    "dataset_cs_clean[\"as_of_date\"] = pd.to_datetime(dataset_cs_clean[\"as_of_date\"])\n",
    "\n",
    "## Final dataset\n",
    "dataset_cs_clean = dataset_cs_clean[cols_to_keep]\n",
    "dataset_cs_clean.name = \"dataset_cs_clean\"\n",
    "\n",
    "\n",
    "## Instead of rewriting the code to perform some data quality checks (outlier, missing rate, zero rate,\n",
    "## and to creates a csv with min/max and some other basic info)\n",
    "## multiple times for each dataset, we have defined a function to do it \n",
    "data_quality_checks_f(dataset_cs_clean)\n",
    "\n",
    "\n",
    "\n",
    "## 3. IoS cleaning ------------------------------------------------------\n",
    "\n",
    "\n",
    "dataset_i_clean = dataset_i.copy()\n",
    "\n",
    "## We will first clean the column names, given the inconsistent format\n",
    "dataset_i_clean.columns = dataset_i_clean.columns.str.replace(r'\\d+', '')\n",
    "dataset_i_clean.columns = dataset_i_clean.columns.str.replace(': Index-1dp', \"\")\n",
    "dataset_i_clean.columns = dataset_i_clean.columns.str.replace(': Index-dp', \"\")\n",
    "dataset_i_clean.columns = dataset_i_clean.columns.str.replace('IoS: ', \"\")\n",
    "dataset_i_clean.columns = dataset_i_clean.columns.str.replace(\"&\", \"\")\n",
    "dataset_i_clean.columns = dataset_i_clean.columns.str.replace(': ', \"\")\n",
    "dataset_i_clean.columns = dataset_i_clean.columns.str.replace('#','')\n",
    "dataset_i_clean.columns = dataset_i_clean.columns.str.replace(\",\",'')\n",
    "dataset_i_clean.columns = dataset_i_clean.columns.str.replace(\"-\",'')\n",
    "dataset_i_clean.columns = [c.replace(' ', '') for c in dataset_i_clean.columns]\n",
    "dataset_i_clean.columns = [x.lower() for x in dataset_i_clean.columns]\n",
    "\n",
    "\n",
    "## We will now create the variables we need and cast them in the appropriate format\n",
    "dataset_i_clean[\"as_of_date\"] = dataset_i_clean.title\n",
    "dataset_i_clean[\"delayable\"] = dataset_i_clean.wholesaleretailtrade.astype(float)\n",
    "dataset_i_clean[\"social\"] = dataset_i_clean.gjdistributiontransportaccommodationfoodservicesandinformationcommunication.astype(float)\n",
    "dataset_i_clean[\"staple\"] = dataset_i_clean.humanhealthactivities.astype(float)\n",
    "dataset_i_clean[\"work_related\"] = dataset_i_clean.htransportationandstorage.astype(float)\n",
    "dataset_i_clean = dataset_i_clean[~(dataset_i_clean.as_of_date.str.len() < 8)]\n",
    "dataset_i_clean[\"year\"] = dataset_i_clean.as_of_date.str[0:4]\n",
    "dataset_i_clean[\"year\"] = pd.to_numeric(dataset_i_clean.year)\n",
    "dataset_i_clean = dataset_i_clean[~(dataset_i_clean.year < 2020)]\n",
    "dataset_i_clean['as_of_date'] = pd.to_datetime(dataset_i_clean['as_of_date'].str[0:5]  + dataset_i_clean['as_of_date'].str[5:6] +  dataset_i_clean['as_of_date'].str[6:8].str.lower(), format='%Y %b')\n",
    "\n",
    "## Final dataset\n",
    "dataset_i_clean = dataset_i_clean[cols_to_keep]\n",
    "dataset_i_clean.name = \"dataset_i_clean\"\n",
    "\n",
    "\n",
    "## Data quality checks with the usual function\n",
    "data_quality_checks_f(dataset_i_clean)\n",
    "\n",
    "\n",
    "\n",
    "## 4. Furlough cleaning ------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "dataset_f_clean = dataset_f.copy()\n",
    "\n",
    "## We will first clean the column names, given the inconsistent format\n",
    "dataset_f_clean.columns = [x.lower() for x in dataset_f_clean.columns]\n",
    "dataset_f_clean.columns = dataset_f_clean.columns.str.replace(\";\",\"\")\n",
    "dataset_f_clean.columns = dataset_f_clean.columns.str.replace(\" \",'_')\n",
    "\n",
    "\n",
    "## We will now create the variables we need as % change from a reference date (Oct-Dec 2019, so pre-Covid) \n",
    "## and cast them in the appropriate format\n",
    "dataset_f_clean[\"as_of_date\"] = dataset_f_clean.date\n",
    "dataset_f_clean[\"as_of_date\"] = pd.to_datetime(dataset_f_clean['as_of_date'])\n",
    "dataset_f_clean[\"f_delayable\"] = dataset_f_clean.wholesale_and_retail_repair_of_motor_vehicles\n",
    "dataset_f_clean[\"f_social\"] = dataset_f_clean.accommodation_and_food_services\n",
    "dataset_f_clean[\"f_staple\"] = dataset_f_clean.health_and_social_work\n",
    "dataset_f_clean[\"f_work_related\"] = dataset_f_clean.transportation_and_storage\n",
    "dataset_e_additional_clean = dataset_e_additional.copy()\n",
    "dataset_e_additional_clean[\"as_of_date\"] = dataset_e_additional_clean[\"Unnamed: 0\"]\n",
    "dataset_e_additional_clean = dataset_e_additional_clean.loc[dataset_e_additional_clean['as_of_date'] == 'Oct-Dec 2019']\n",
    "dataset_e_additional_clean['as_of_date'] = pd.to_datetime(dataset_e_additional_clean['as_of_date'].str[8:12] + dataset_e_additional_clean['as_of_date'].str[4:7], format='%Y%b')\n",
    "dataset_e_additional_clean[\"a_delayable\"] = dataset_e_additional_clean[\"Wholesale, retail & repair of motor vehicles\"]\n",
    "dataset_e_additional_clean[\"a_social\"] = dataset_e_additional_clean[\"Accommod-ation & food services\"]\n",
    "dataset_e_additional_clean[\"a_staple\"] = dataset_e_additional_clean[\"Human health & social work activities\"]\n",
    "dataset_e_additional_clean[\"a_work_related\"] = dataset_e_additional_clean[\"Transport & storage\"]\n",
    "dataset_e_additional_clean = dataset_e_additional_clean[cols_to_keep_ea]\n",
    "dataset_f_clean[\"a_delayable\"] = int(dataset_e_additional_clean[\"a_delayable\"])\n",
    "dataset_f_clean[\"a_social\"] = int(dataset_e_additional_clean[\"a_social\"])\n",
    "dataset_f_clean[\"a_staple\"] = int(dataset_e_additional_clean[\"a_staple\"])\n",
    "dataset_f_clean[\"a_work_related\"] = int(dataset_e_additional_clean[\"a_work_related\"])\n",
    "dataset_f_clean[\"delayable\"] = dataset_f_clean.f_delayable.astype(float)/dataset_f_clean.a_delayable.astype(float)\n",
    "dataset_f_clean[\"social\"] = dataset_f_clean.f_social.astype(float)/dataset_f_clean.a_social.astype(float)\n",
    "dataset_f_clean[\"staple\"] = dataset_f_clean.f_staple.astype(float)/dataset_f_clean.a_staple.astype(float)\n",
    "dataset_f_clean[\"work_related\"] = dataset_f_clean.f_work_related.astype(float)/dataset_f_clean.a_work_related.astype(float)\n",
    "\n",
    "## Final dataset\n",
    "dataset_f_clean = dataset_f_clean[cols_to_keep]\n",
    "dataset_f_clean.name = \"dataset_f_clean\"\n",
    "\n",
    "## Data quality checks with the usual function\n",
    "data_quality_checks_f(dataset_f_clean)\n",
    "\n",
    "\n",
    "\n",
    "## 5. Employment cleaning ------------------------------------------------------\n",
    "\n",
    "\n",
    "dataset_e_clean = dataset_e.copy()\n",
    "\n",
    "## We will first clean the column names, given the inconsistent format\n",
    "dataset_e_clean[\"as_of_date\"] = dataset_e_clean[\"Unnamed: 0\"]\n",
    "\n",
    "\n",
    "## We will now create the variables we need and cast them in the appropriate format\n",
    "dataset_e_clean[\"delayable\"] = dataset_e_clean[\"Wholesale, retail & repair of motor vehicles\"].astype(float)\n",
    "dataset_e_clean[\"social\"] = dataset_e_clean[\"Accommod-ation & food services\"].astype(float)\n",
    "dataset_e_clean[\"staple\"] = dataset_e_clean[\"Human health & social work activities\"].astype(float)\n",
    "dataset_e_clean[\"work_related\"] = dataset_e_clean[\"Transport & storage\"].astype(float)\n",
    "dataset_e_clean['as_of_date'] = pd.to_datetime(dataset_e_clean['as_of_date'].str[8:12] + dataset_e_clean['as_of_date'].str[4:7], format='%Y%b')\n",
    "\n",
    "## Final dataset\n",
    "dataset_e_clean = dataset_e_clean[cols_to_keep]\n",
    "dataset_e_clean.name = \"dataset_e_clean\"\n",
    "\n",
    "## Reshape of additional emplyment data\n",
    "dataset_e_additional_clean_2 = pd.melt(dataset_e_additional_clean, id_vars = \"as_of_date\")\n",
    "dataset_e_additional_clean_2 = dataset_e_additional_clean_2.rename(columns={'value': 'average_pre_cv'})\n",
    "\n",
    "## Data quality checks with the usual function\n",
    "data_quality_checks_f(dataset_e_clean)\n",
    "\n",
    "\n",
    "## 5. Vacancies cleaning ------------------------------------------------------\n",
    "\n",
    "\n",
    "dataset_v_clean = dataset_v.copy()\n",
    "\n",
    "## We will first clean the column names, given the inconsistent format\n",
    "dataset_v_clean[\"as_of_date\"] = dataset_v_clean[\"SIC 2007 sections\"]\n",
    "\n",
    "## We will now create the variables we need and cast them in the appropriate format\n",
    "dataset_v_clean[\"delayable\"] = dataset_v_clean[\"Wholesale & retail trade; repair of motor vehicles and motor cycles\"].astype(float)\n",
    "dataset_v_clean[\"social\"] = dataset_v_clean[\"Accomoda-tion & food service activities\"].astype(float)\n",
    "dataset_v_clean[\"staple\"] = dataset_v_clean[\"Human health & social work activities\"].astype(float)\n",
    "dataset_v_clean[\"work_related\"] = dataset_v_clean[\"Transport & storage\"].astype(float)\n",
    "dataset_v_clean[\"year\"] = dataset_v_clean.as_of_date.str[8:12]\n",
    "dataset_v_clean[\"year\"] = pd.to_numeric(dataset_v_clean.year)\n",
    "dataset_v_clean = dataset_v_clean[~(dataset_v_clean.year < 2020)]\n",
    "dataset_v_clean['as_of_date'] = pd.to_datetime(dataset_v_clean['as_of_date'].str[8:12] + dataset_v_clean['as_of_date'].str[4:7], format='%Y%b')\n",
    "\n",
    "## Final dataset\n",
    "dataset_v_clean = dataset_v_clean[cols_to_keep]\n",
    "dataset_v_clean.name = \"dataset_v_clean\"\n",
    "\n",
    "## Data quality checks with the usual function\n",
    "data_quality_checks_f(dataset_v_clean)\n",
    "\n",
    "\n",
    "\n",
    "## 6. Join the data and check final sample -----------------------------------\n",
    "\n",
    "\n",
    "## First, we create a range of dates to use as common joining list\n",
    "## given that the datasets span different time periods\n",
    "list_name = pd.date_range(\"2020-03-04\",\"2021-03-31\",freq='d').tolist()\n",
    "dates_list = pd.DataFrame (list_name, columns = ['as_of_date'])\n",
    "dates_list[\"as_of_date\"] = pd.to_datetime(dates_list['as_of_date'])\n",
    "\n",
    "## Checking if some dates are completely missing \n",
    "## (so NOT if a column has missings values in it, despite having a date asociated with it - which is taken care of by the funcion  \"00_data_quality_checks\" -\n",
    "## but to see if entire dates are completely missing)\n",
    "test_cs = dates_list.merge(dataset_cs_clean, on = \"as_of_date\")\n",
    "test_cs = test_cs[test_cs['as_of_date'].dt.dayofweek < 5] ## Only 8 non-weekend dates missing, corresponding to bank holidays\n",
    "\n",
    "\n",
    "test_f = dates_list.merge(dataset_f_clean, on = \"as_of_date\")\n",
    "test_f = test_f.staple.notna() ## The missing values in _f dataset are March 2020 and March 2021, due to the fact that the dataset itself starts and ends after/before that\n",
    "\n",
    "\n",
    "## Filling in the missing values\n",
    "additional_cleaning_cs = dates_list.merge(dataset_cs_clean, on = \"as_of_date\")\n",
    "additional_cleaning_cs = additional_cleaning_cs.fillna(method='ffill')\n",
    "\n",
    "\n",
    "## Reshaping the datasets to allow for a clean output\n",
    "dataset_cs_clean = pd.melt(dataset_cs_clean, id_vars = \"as_of_date\")\n",
    "dataset_cs_clean = dataset_cs_clean.rename(columns={'value': 'c_value'})\n",
    "dataset_i_clean = pd.melt(dataset_i_clean, id_vars = \"as_of_date\")\n",
    "dataset_i_clean = dataset_i_clean.rename(columns={'value': 'i_value'})\n",
    "dataset_f_clean = pd.melt(dataset_f_clean, id_vars = \"as_of_date\")\n",
    "dataset_f_clean = dataset_f_clean.rename(columns={'value': 'f_value'})\n",
    "dataset_e_clean = pd.melt(dataset_e_clean, id_vars = \"as_of_date\")\n",
    "dataset_e_clean = dataset_e_clean.rename(columns={'value': 'e_value'})\n",
    "dataset_v_clean = pd.melt(dataset_v_clean, id_vars = \"as_of_date\")\n",
    "dataset_v_clean = dataset_v_clean.rename(columns={'value': 'v_value'})\n",
    "additional_cleaning_cs = pd.melt(additional_cleaning_cs, id_vars = \"as_of_date\")\n",
    "additional_cleaning_cs = additional_cleaning_cs.rename(columns={'value': 'c_value'})\n",
    "\n",
    "## Final dataset\n",
    "final_daily_dataset = reduce(lambda left,right: pd.merge(left,right,on=['as_of_date', \"variable\"], how='left'), [additional_cleaning_cs, dataset_i_clean, dataset_f_clean, dataset_e_clean, dataset_v_clean])\n",
    "final_daily_dataset.to_csv(\"final_daily_dataset.csv\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
